# ğŸ¤– AI-Powered Support Assistant

A full-stack AI-powered support assistant built with React, Python/FastAPI, SQLite, and Google Gemini AI. The assistant answers user questions strictly based on product documentation using RAG (Retrieval-Augmented Generation) with TF-IDF similarity search, maintains session-wise conversation context, and provides real-time streaming responses with live status updates.

**Python FastAPI** | **React** | **SQLite** | **Gemini**

## âœ¨ Features

### Core Features
*   **ğŸ’¬ AI Chat Interface** â€” Beautiful chat UI with user/assistant message bubbles
*   **ğŸ“„ Document-Grounded Answering** â€” AI only answers from docs.json, refuses unknown questions
*   **ğŸ” RAG with Vector Search** â€” Finds relevant docs instead of sending full knowledge base
*   **ğŸ§  Conversation Memory** â€” Last 5 message pairs as context from SQLite
*   **ğŸ“ Session Management** â€” UUID-based sessions stored in localStorage
*   **ğŸ’¾ SQLite Persistence** â€” All messages and sessions stored in SQLite database

### Bonus Features
*   **âš¡ Real-time Streaming** â€” Word-by-word responses via Server-Sent Events (SSE)
*   **ğŸ”„ Live Status Updates** â€” Shows "Searching docs..." â†’ "Analyzing context..." â†’ "Generating..." stages
*   **ğŸ“ Markdown Rendering** â€” AI responses rendered with proper formatting
*   **ğŸ³ Docker Support** â€” Full Dockerfiles + docker-compose.yml
*   **ğŸ›¡ï¸ Rate Limiting** â€” Per-IP rate limiting on all endpoints

### UI Features
*   **ğŸ¨ Premium Glassmorphic Dark UI** â€” Stunning dark theme with glass effects
*   **âœ¨ Smooth Animations** â€” Message entry animations, typing indicator, status pulses
*   **ğŸ“± Fully Responsive** â€” Works on desktop, tablet, and mobile
*   **ğŸ’¡ Suggestion Chips** â€” Pre-built questions for easy onboarding
*   **ğŸ“‹ Session Sidebar** â€” Browse, switch, and delete past conversations
*   **ğŸ†• New Chat Button** â€” Start fresh conversations anytime

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
| :--- | :--- |
| **Frontend** | React 18, Vite, TailwindCSS v4, Lucide Icons, React Markdown, Framer Motion |
| **Backend** | Python, FastAPI |
| **Database** | SQLite (via ChromaDB/local vector store) |
| **AI/LLM** | Google Gemini 2.0 Flash / Langchain |
| **Containerization**| Docker + docker-compose |

## ï¿½ Project Structure

```text
OVI-AssistAI/
â”œâ”€â”€ frontend/                        # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatHeader.jsx      # Header with branding
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.jsx     # Renders all messages
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageItem.jsx     # Individual message bubble
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageInput.jsx    # Input + send button
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TypingIndicator.jsx # Animated typing dots
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ StatusIndicator.jsx # Live status stages
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SuggestionChips.jsx # Quick question suggestions
â”‚   â”‚   â”‚   â””â”€â”€ sidebar/
â”‚   â”‚   â”‚       â””â”€â”€ SessionSidebar.jsx  # Session list + controls
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ ChatPage.jsx           # Main page (orchestrates everything)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ chatService.js         # API calls (axios + fetch for SSE)
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ session.js             # Session ID + timestamp utils
â”‚   â”‚   â”œâ”€â”€ App.jsx                    # Root component
â”‚   â”‚   â”œâ”€â”€ main.jsx                   # Entry point
â”‚   â”‚   â””â”€â”€ index.css                  # Design system (Tailwind v4)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vercel.json                    # Vercel rules
â”‚
â”œâ”€â”€ backend/                          # FastAPI Backend
â”‚   â”œâ”€â”€ data/                           # Stored documents and vector DB
â”‚   â”œâ”€â”€ routes/                         # API endpoint definitions
â”‚   â”œâ”€â”€ services/                       # Core business logic and LLM orchestration
â”‚   â”œâ”€â”€ scripts/                        # Data ingestion and utility scripts
â”‚   â”œâ”€â”€ main.py                         # Application entry point
â”‚   â”œâ”€â”€ config.py                       # Configuration management
â”‚   â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ docker-compose.yml                # Container orchestration
â””â”€â”€ README.md                         # This file
```

## ï¿½ Quick Start

### Prerequisites
*   Node.js 20+ (check: `node --version`)
*   Python 3.9+ (check: `python --version`)
*   Google Gemini API key â€” Get free at `aistudio.google.com/apikey`

### 1. Clone & Install
```bash
# Clone the repository
git clone https://github.com/anjim999/OVI-AssistAI.git
cd OVI-AssistAI

# Install backend dependencies
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Install frontend dependencies
cd ../frontend
npm install
```

### 2. Configure Environment

**Backend environment**
```bash
cd backend
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY
```

**Frontend environment**
```bash
cd frontend
cp .env.example .env
# Edit .env and add:
# VITE_API_R_URL=http://localhost:8000
```

### 3. Run Development Servers

```bash
# Terminal 1 â€” Backend (port 8000)
cd backend
uvicorn main:app --reload --port 8000

# Terminal 2 â€” Frontend (port 5173)
cd frontend
npm run dev
```

### 4. Open Browser
Visit `http://localhost:5173`

## ğŸ”‘ API Documentation

Base URL: `http://localhost:8000/api`

### âœ… POST `/api/chat` â€” Send Message
Send a user message and receive an AI response.

**Request:**
```json
{
    "sessionId": "550e8400-e29b-41d4-a716-446655440000",
    "message": "How can I reset my password?"
}
```

### âœ… POST `/api/chat/stream` â€” Send Message (Streaming)
Same as `/api/chat` but returns Server-Sent Events with live status updates.

### âœ… GET `/api/conversations/:sessionId` â€” Get Conversation
Returns all messages for a session in chronological order.

### âœ… GET `/api/sessions` â€” List All Sessions

### âœ… DELETE `/api/sessions/:sessionId` â€” Delete Session
Deletes a session and all its messages.

### âœ… GET `/health` â€” Health Check

## ğŸ³ Docker Deployment
```bash
# Build and run both services
docker-compose up --build

# Frontend: http://localhost:80
# Backend:  http://localhost:8000
```

## ğŸš€ Deployment (Vercel + Render)

### Frontend â†’ Vercel
1. Push your code to GitHub
2. Go to vercel.com â†’ Import Project
3. Select the `frontend` folder as the root directory
4. Set Framework: Vite
5. Add Environment Variable:
   * `VITE_API_R_URL = https://ovi-assistai.onrender.com`
6. Deploy!

### Backend â†’ Render
1. Go to render.com â†’ New Web Service
2. Connect your GitHub repo
3. Configure:
   * Root Directory: `backend`
   * Build Command: `pip install -r requirements.txt`
   * Start Command: `uvicorn main:app --host 0.0.0.0 --port $PORT`
   * Environment: Python
4. Add Environment Variables:
   * `GEMINI_API_KEY = your Gemini API key`
5. Deploy!

## ğŸŒ Live Demo

Built with â¤ï¸ for the OVI Assist AI Assignment

**Frontend:** https://ovi-assist-ai.vercel.app/

**Backend:** https://ovi-assistai.onrender.com
